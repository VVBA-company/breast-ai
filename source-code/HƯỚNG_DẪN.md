# ğŸ“š HÆ¯á»šNG DáºªN CHI TIáº¾T FILE MAIN.IPYNB

> **DÃ nh cho ngÆ°á»i má»›i báº¯t Ä‘áº§u** - Giáº£i thÃ­ch tá»«ng bÆ°á»›c xá»­ lÃ½ dá»¯ liá»‡u vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n ung thÆ° vÃº

---

## ğŸ¯ Má»¤C ÄÃCH Dá»° ÃN

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh AI Ä‘á»ƒ **dá»± Ä‘oÃ¡n loáº¡i ung thÆ° vÃº chi tiáº¿t** cá»§a bá»‡nh nhÃ¢n dá»±a trÃªn cÃ¡c thÃ´ng tin lÃ¢m sÃ ng nhÆ°:

- Loáº¡i pháº«u thuáº­t Ä‘Ã£ thá»±c hiá»‡n
- CÃ¡c chá»‰ sá»‘ y táº¿ (HER2, PR status...)
- PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ (hÃ³a trá»‹, xáº¡ trá»‹...)
- CÃ¡c thÃ´ng sá»‘ sinh há»c khÃ¡c

**Káº¿t quáº£ dá»± Ä‘oÃ¡n:** 5 loáº¡i ung thÆ° vÃº chi tiáº¿t

- 0: Breast (Ung thÆ° vÃº chung)
- 1: Breast Invasive Ductal Carcinoma (Ung thÆ° biá»ƒu mÃ´ á»‘ng xÃ¢m láº¥n)
- 2: Breast Invasive Lobular Carcinoma (Ung thÆ° tiá»ƒu thÃ¹y xÃ¢m láº¥n)
- 3: Breast Invasive Mixed Mucinous Carcinoma (Ung thÆ° nháº§y há»—n há»£p xÃ¢m láº¥n)
- 4: Breast Mixed Ductal and Lobular Carcinoma (Ung thÆ° á»‘ng vÃ  tiá»ƒu thÃ¹y há»—n há»£p)

---

## ğŸ“‚ Dá»® LIá»†U: METABRIC Dataset

### ThÃ´ng tin dataset

- **TÃªn file:** `dataset/METABRIC_RNA_Mutation.csv`
- **Nguá»“n:** METABRIC (Molecular Taxonomy of Breast Cancer International Consortium)
- **KÃ­ch thÆ°á»›c:** 1,906 bá»‡nh nhÃ¢n (dÃ²ng) Ã— hÆ¡n 700 cá»™t thÃ´ng tin
- **Ná»™i dung:** ThÃ´ng tin lÃ¢m sÃ ng + dá»¯ liá»‡u gene expression + Ä‘á»™t biáº¿n gen

### Cáº¥u trÃºc dá»¯ liá»‡u gá»‘c

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ METABRIC Dataset (1906 patients Ã— 700+ columns)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ 1. THÃ”NG TIN Bá»†NH NHÃ‚N                                         â”‚
â”‚    â€¢ patient_id                    : MÃ£ bá»‡nh nhÃ¢n              â”‚
â”‚    â€¢ age_at_diagnosis              : Tuá»•i khi cháº©n Ä‘oÃ¡n        â”‚
â”‚    â€¢ type_of_breast_surgery        : Loáº¡i pháº«u thuáº­t           â”‚
â”‚    â€¢ cancer_type                   : Loáº¡i ung thÆ° chung        â”‚
â”‚    â€¢ cancer_type_detailed          : Loáº¡i ung thÆ° chi tiáº¿t â­  â”‚
â”‚                                                                 â”‚
â”‚ 2. THÃ”NG Sá» LÃ‚M SÃ€NG                                           â”‚
â”‚    â€¢ cellularity                   : Máº­t Ä‘á»™ táº¿ bÃ o             â”‚
â”‚    â€¢ neoplasm_histologic_grade     : Äá»™ mÃ´ há»c (1-3)           â”‚
â”‚    â€¢ lymph_nodes_examined_positive : Sá»‘ háº¡ch báº¡ch huyáº¿t (+)    â”‚
â”‚    â€¢ nottingham_prognostic_index   : Chá»‰ sá»‘ tiÃªn lÆ°á»£ng         â”‚
â”‚    â€¢ tumor_size                    : KÃ­ch thÆ°á»›c khá»‘i u         â”‚
â”‚    â€¢ tumor_stage                   : Giai Ä‘oáº¡n ung thÆ°         â”‚
â”‚                                                                 â”‚
â”‚ 3. THÃ”NG Sá» SINH Há»ŒC                                           â”‚
â”‚    â€¢ pam50_+_claudin-low_subtype   : PhÃ¢n loáº¡i PAM50           â”‚
â”‚    â€¢ her2_status                   : Tráº¡ng thÃ¡i HER2           â”‚
â”‚    â€¢ pr_status                     : Tráº¡ng thÃ¡i PR             â”‚
â”‚    â€¢ er_status                     : Tráº¡ng thÃ¡i ER             â”‚
â”‚                                                                 â”‚
â”‚ 4. PHÆ¯Æ NG PHÃP ÄIá»€U TRá»Š                                        â”‚
â”‚    â€¢ chemotherapy                  : HÃ³a trá»‹ (0=No, 1=Yes)    â”‚
â”‚    â€¢ hormone_therapy               : Liá»‡u phÃ¡p hormone         â”‚
â”‚    â€¢ radio_therapy                 : Xáº¡ trá»‹                    â”‚
â”‚                                                                 â”‚
â”‚ 5. Dá»® LIá»†U GENE (600+ cá»™t)                                     â”‚
â”‚    â€¢ brca1, brca2, tp53, pik3ca, ...                          â”‚
â”‚    â€¢ Expression levels cá»§a hÃ ng trÄƒm gene                      â”‚
â”‚    â€¢ Mutation data (cÃ³/khÃ´ng Ä‘á»™t biáº¿n)                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â­ = TARGET (Biáº¿n cáº§n dá»± Ä‘oÃ¡n)
```

### VÃ­ dá»¥ dá»¯ liá»‡u thá»±c táº¿

| patient_id | age   | surgery           | cancer_type   | **cancer_type_detailed**             | cellularity | her2     | pr       |
| ---------- | ----- | ----------------- | ------------- | ------------------------------------ | ----------- | -------- | -------- |
| 0          | 75.65 | MASTECTOMY        | Breast Cancer | **Breast Invasive Ductal Carcinoma** | High        | Negative | Negative |
| 2          | 43.19 | BREAST CONSERVING | Breast Cancer | **Breast Invasive Ductal Carcinoma** | High        | Negative | Positive |
| 5          | 48.87 | MASTECTOMY        | Breast Cancer | **Breast Invasive Ductal Carcinoma** | High        | Negative | Positive |

---

## ğŸ”„ QUY TRÃŒNH Xá»¬ LÃ Dá»® LIá»†U (10 BÆ¯á»šC)

### **BÆ¯á»šC 1: Import thÆ° viá»‡n vÃ  Ä‘á»c dá»¯ liá»‡u**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from imblearn.over_sampling import SMOTENC
```

**Giáº£i thÃ­ch:**

- `pandas`: Xá»­ lÃ½ báº£ng dá»¯ liá»‡u (giá»‘ng Excel)
- `numpy`: TÃ­nh toÃ¡n sá»‘ há»c
- `matplotlib, seaborn`: Váº½ biá»ƒu Ä‘á»“
- `sklearn`: ThÆ° viá»‡n machine learning
- `imblearn`: Xá»­ lÃ½ dá»¯ liá»‡u máº¥t cÃ¢n báº±ng

```python
df = pd.read_csv("dataset/METABRIC_RNA_Mutation.csv")
```

**Káº¿t quáº£:** Äá»c file CSV vÃ o biáº¿n `df` (DataFrame)

---

### **BÆ¯á»šC 2: Kiá»ƒm tra dá»¯ liá»‡u thiáº¿u (Missing Values)**

```python
na_counts = df.isna().sum()
na_counts = na_counts[na_counts > 0]
print(na_counts)
```

**Táº¡i sao quan trá»ng?**

- Giá»‘ng nhÆ° kháº£o sÃ¡t: má»™t sá»‘ ngÆ°á»i khÃ´ng Ä‘iá»n Ä‘á»§ thÃ´ng tin
- VÃ­ dá»¥: Bá»‡nh nhÃ¢n A khÃ´ng Ä‘o HER2 â†’ Ã´ "her2_status" bá»‹ trá»‘ng
- Machine learning khÃ´ng thá»ƒ xá»­ lÃ½ Ã´ trá»‘ng â†’ cáº§n xá»­ lÃ½

**VÃ­ dá»¥ output:**

```
cellularity                      67  â† 67 bá»‡nh nhÃ¢n thiáº¿u thÃ´ng tin nÃ y
her2_status                     184  â† 184 bá»‡nh nhÃ¢n thiáº¿u
nottingham_prognostic_index     189
```

---

### **BÆ¯á»šC 3: Lá»±a chá»n Ä‘áº·c trÆ°ng quan trá»ng (Feature Selection)**

#### â“ Váº¥n Ä‘á»

Dataset gá»‘c cÃ³ hÆ¡n 700 cá»™t, nhÆ°ng:

- Nhiá»u cá»™t lÃ  gene expression (khÃ´ng cáº§n thiáº¿t cho dá»± Ä‘oÃ¡n lÃ¢m sÃ ng)
- QuÃ¡ nhiá»u thÃ´ng tin â†’ model phá»©c táº¡p, khÃ³ train, dá»… overfitting

#### âœ… Giáº£i phÃ¡p: Chá»‰ giá»¯ láº¡i 13 cá»™t quan trá»ng nháº¥t

```python
KEEP = [
    "type_of_breast_surgery",           # Loáº¡i pháº«u thuáº­t
    "cancer_type",                       # Loáº¡i ung thÆ° chung
    "cancer_type_detailed",              # â­ TARGET - Cáº§n dá»± Ä‘oÃ¡n
    "cellularity",                       # Máº­t Ä‘á»™ táº¿ bÃ o
    "chemotherapy",                      # CÃ³ hÃ³a trá»‹ khÃ´ng (0/1)
    "pam50_+_claudin-low_subtype",      # PhÃ¢n loáº¡i PAM50
    "neoplasm_histologic_grade",        # Äá»™ mÃ´ há»c (1/2/3)
    "her2_status",                       # Tráº¡ng thÃ¡i HER2
    "hormone_therapy",                   # CÃ³ liá»‡u phÃ¡p hormone khÃ´ng
    "lymph_nodes_examined_positive",    # Sá»‘ háº¡ch báº¡ch huyáº¿t dÆ°Æ¡ng tÃ­nh
    "nottingham_prognostic_index",      # Chá»‰ sá»‘ tiÃªn lÆ°á»£ng
    "pr_status",                         # Tráº¡ng thÃ¡i PR
    "radio_therapy",                     # CÃ³ xáº¡ trá»‹ khÃ´ng
]

df_features = df[KEEP]  # Chá»‰ láº¥y 13 cá»™t nÃ y
```

**Káº¿t quáº£:**

- Tá»« 1906 Ã— 700+ â†’ 1906 Ã— 13 (giáº£m 98% sá»‘ cá»™t!)
- Giá»¯ láº¡i Ä‘á»§ thÃ´ng tin y khoa quan trá»ng Ä‘á»ƒ dá»± Ä‘oÃ¡n

---

### **BÆ¯á»šC 4: PhÃ¢n loáº¡i loáº¡i dá»¯ liá»‡u**

Trong 13 cá»™t Ä‘Ã£ chá»n, cÃ³ 2 loáº¡i dá»¯ liá»‡u:

#### 1ï¸âƒ£ **Categorical (Dáº¡ng chá»¯/phÃ¢n loáº¡i)**

```python
Categorical = [
    "type_of_breast_surgery",      # MASTECTOMY hoáº·c BREAST CONSERVING
    "cancer_type",                  # Breast Cancer hoáº·c Breast Sarcoma
    "cancer_type_detailed",         # 5 loáº¡i khÃ¡c nhau
    "cellularity",                  # High, Moderate, Low
    "pam50_+_claudin-low_subtype",  # Basal, Her2, LumA, LumB, ...
    "her2_status",                  # Positive, Negative
    "pr_status"                     # Positive, Negative
]
```

**VÃ­ dá»¥ giÃ¡ trá»‹:**

- `her2_status`: "Positive" hoáº·c "Negative" (khÃ´ng pháº£i sá»‘)
- `cellularity`: "High", "Moderate", "Low" (khÃ´ng cÃ³ thá»© tá»± sá»‘)

#### 2ï¸âƒ£ **Numerical (Dáº¡ng sá»‘)**

```python
Numerical = [
    "chemotherapy",                     # 0 hoáº·c 1
    "neoplasm_histologic_grade",        # 1, 2, hoáº·c 3
    "hormone_therapy",                  # 0 hoáº·c 1
    "lymph_nodes_examined_positive",    # 0, 1, 2, 3, ...
    "nottingham_prognostic_index",      # 2.04, 3.58, 5.4, ...
    "radio_therapy"                     # 0 hoáº·c 1
]
```

---

### **BÆ¯á»šC 5: Trá»±c quan hÃ³a dá»¯ liá»‡u (Visualization)**

```python
for col in Categorical:
    sns.countplot(data=df, x=col)
    plt.show()
```

**Má»¥c Ä‘Ã­ch:** Xem phÃ¢n bá»‘ dá»¯ liá»‡u qua biá»ƒu Ä‘á»“ cá»™t

**VÃ­ dá»¥ biá»ƒu Ä‘á»“ cho `cancer_type_detailed`:**

```
Breast Invasive Ductal Carcinoma     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1200
Breast Invasive Lobular Carcinoma    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 400
Breast                               â–ˆâ–ˆâ–ˆ 150
Breast Mixed Ductal and Lobular      â–ˆâ–ˆ 100
Breast Invasive Mixed Mucinous       â–ˆ 56
```

**PhÃ¡t hiá»‡n váº¥n Ä‘á»:**

- âš ï¸ **Class Imbalance** (Máº¥t cÃ¢n báº±ng nhÃ£n)
- Class 1 cÃ³ 1200 máº«u, Class 4 chá»‰ cÃ³ 56 máº«u
- â†’ Model sáº½ thiÃªn vá» class Ä‘Ã´ng ngÆ°á»i hÆ¡n

---

### **BÆ¯á»šC 6: XÃ³a dá»¯ liá»‡u thiáº¿u (Handle Missing Values)**

```python
df_features = df_features.dropna()
print("Shape sau khi xÃ³a:", df_features.shape)
```

**TrÆ°á»›c:** 1906 dÃ²ng  
**Sau:** ~1600 dÃ²ng (xÃ³a ~300 dÃ²ng cÃ³ Ã´ trá»‘ng)

#### â“ Táº¡i sao xÃ³a thay vÃ¬ Ä‘iá»n giÃ¡ trá»‹?

**CÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘iá»n thÆ°á»ng tháº¥y:**

1. Äiá»n giÃ¡ trá»‹ trung bÃ¬nh (mean/median)
2. Äiá»n giÃ¡ trá»‹ xuáº¥t hiá»‡n nhiá»u nháº¥t (mode)
3. Äiá»n báº±ng thuáº­t toÃ¡n dá»± Ä‘oÃ¡n

**Váº¥n Ä‘á» vá»›i dá»¯ liá»‡u y khoa:**

```
VÃ­ dá»¥: Bá»‡nh nhÃ¢n A khÃ´ng Ä‘o HER2
âŒ Äiá»n "Positive" â†’ Sai lá»‡ch thÃ´ng tin
âŒ Äiá»n "Negative" â†’ CÅ©ng sai lá»‡ch
âœ… XÃ³a bá»‡nh nhÃ¢n nÃ y â†’ An toÃ n hÆ¡n
```

**NguyÃªn táº¯c:** Trong y táº¿, tá»‘t hÆ¡n lÃ  máº¥t máº«u tháº­t cÃ²n hÆ¡n máº«u giáº£!

---

### **BÆ¯á»šC 7: MÃ£ hÃ³a dá»¯ liá»‡u (Label Encoding)**

#### â“ Váº¥n Ä‘á»: MÃ¡y tÃ­nh khÃ´ng hiá»ƒu chá»¯!

```
Machine Learning khÃ´ng Ä‘á»c Ä‘Æ°á»£c:
âŒ "Positive", "Negative"
âŒ "High", "Moderate", "Low"
âœ… Chá»‰ hiá»ƒu: 0, 1, 2, 3, ...
```

#### âœ… Giáº£i phÃ¡p: Chuyá»ƒn chá»¯ â†’ sá»‘

```python
from sklearn.preprocessing import LabelEncoder

encoding_maps = {}

for col in categorical_cols:
    le = LabelEncoder()
    df_features[col] = le.fit_transform(df_features[col])

    # LÆ°u báº£ng chuyá»ƒn Ä‘á»•i
    encoding_maps[col] = {
        cls: int(code)
        for cls, code in zip(le.classes_, le.transform(le.classes_))
    }

# LÆ°u ra file JSON Ä‘á»ƒ dÃ¹ng sau
import json
with open("encoding_maps.json", "w") as f:
    json.dump(encoding_maps, f, indent=4)
```

**VÃ­ dá»¥ báº£ng mÃ£ hÃ³a:**

| Cá»™t             | GiÃ¡ trá»‹ gá»‘c | GiÃ¡ trá»‹ sau mÃ£ hÃ³a |
| --------------- | ----------- | ------------------ |
| `her2_status`   | "Negative"  | 0                  |
| `her2_status`   | "Positive"  | 1                  |
| `cellularity`   | "High"      | 0                  |
| `cellularity`   | "Low"       | 1                  |
| `cellularity`   | "Moderate"  | 2                  |
| `pam50_subtype` | "Basal"     | 0                  |
| `pam50_subtype` | "Her2"      | 1                  |
| `pam50_subtype` | "LumA"      | 2                  |
| `pam50_subtype` | "LumB"      | 3                  |

**Káº¿t quáº£:**

```python
# TrÆ°á»›c mÃ£ hÃ³a
her2_status: ["Positive", "Negative", "Positive"]

# Sau mÃ£ hÃ³a
her2_status: [1, 0, 1]
```

**Táº¡i sao lÆ°u `encoding_maps.json`?**

- Khi dá»± Ä‘oÃ¡n máº«u má»›i, cáº§n chuyá»ƒn "Positive" â†’ 1
- Backend API sáº½ dÃ¹ng file nÃ y Ä‘á»ƒ encode input

---

### **BÆ¯á»šC 8: CÃ¢n báº±ng dá»¯ liá»‡u (SMOTENC)**

#### â“ Váº¥n Ä‘á»: Class Imbalance

```
PhÃ¢n bá»‘ thá»±c táº¿:
Class 0: â–ˆâ–ˆâ–ˆ 150 máº«u (7%)
Class 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1200 máº«u (75%)  â† ÄÃ´ng nháº¥t!
Class 2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 400 máº«u (25%)
Class 3: â–ˆ 56 máº«u (3%)
Class 4: â–ˆâ–ˆ 100 máº«u (6%)
```

**Há»‡ quáº£:**

- Model há»c thiÃªn vá» Class 1 (vÃ¬ cÃ³ nhiá»u máº«u nháº¥t)
- Vá»›i Class 3, 4 (Ã­t máº«u) â†’ Model dá»± Ä‘oÃ¡n kÃ©m

**VÃ­ dá»¥ thá»±c táº¿:**

```
Model "lÆ°á»i": "Má»i bá»‡nh nhÃ¢n Ä‘á»u lÃ  Class 1!"
â†’ Accuracy: 75% (Ä‘Ãºng 1200/1600)
â†’ NhÆ°ng khÃ´ng dá»± Ä‘oÃ¡n Ä‘Ãºng Ä‘Æ°á»£c Class 3, 4!
```

#### âœ… Giáº£i phÃ¡p: SMOTENC

**SMOTE = Synthetic Minority Over-sampling Technique**

- Táº¡o thÃªm máº«u "giáº£" cho cÃ¡c class thiá»ƒu sá»‘
- **SMOTENC**: PhiÃªn báº£n Ä‘áº·c biá»‡t cho dá»¯ liá»‡u **cÃ³ cáº£ categorical + numerical**

```python
from imblearn.over_sampling import SMOTENC
from collections import Counter

# XÃ¡c Ä‘á»‹nh cá»™t categorical (dáº¡ng chá»¯)
X = df_features.drop(columns=["cancer_type_detailed"])  # Features
y = df_features["cancer_type_detailed"]                 # Target

categorical_feature_indices = [
    X.columns.get_loc(c) for c in categorical_cols
]

# TÃ­nh k_neighbors (sá»‘ lÃ¡ng giá»ng Ä‘á»ƒ táº¡o máº«u má»›i)
counts = Counter(y)
min_count = min(counts.values())  # Class Ã­t máº«u nháº¥t cÃ³ bao nhiÃªu
k_neighbors = min(5, max(1, min_count - 1))

print(f"TrÆ°á»›c SMOTENC: {counts}")
# Output: {0: 150, 1: 1200, 2: 400, 3: 56, 4: 100}

# Ãp dá»¥ng SMOTENC
sampler = SMOTENC(
    categorical_features=categorical_feature_indices,
    k_neighbors=k_neighbors,
    random_state=42
)
X_res, y_res = sampler.fit_resample(X.values, y)

# Ghi Ä‘Ã¨ láº¡i df_features
X_res_df = pd.DataFrame(X_res, columns=X.columns)
y_res_series = pd.Series(y_res, name="cancer_type_detailed")
df_features = pd.concat([X_res_df, y_res_series], axis=1)

print(f"Sau SMOTENC: {Counter(y_res)}")
# Output: {0: 1200, 1: 1200, 2: 1200, 3: 1200, 4: 1200}
```

**CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a SMOTENC:**

```
1. Chá»n 1 máº«u tá»« class thiá»ƒu sá»‘ (vÃ­ dá»¥ Class 3)
2. TÃ¬m k lÃ¡ng giá»ng gáº§n nháº¥t (k=5)
3. Táº¡o máº«u má»›i náº±m giá»¯a máº«u gá»‘c vÃ  lÃ¡ng giá»ng

Máº«u gá»‘c:    â—
LÃ¡ng giá»ng: â—‹ â—‹ â—‹ â—‹ â—‹
Máº«u má»›i:    â—† â—† â—† (náº±m giá»¯a khoáº£ng)

â†’ Táº¡o Ä‘áº¿n khi Class 3 = Class 1 (cÃ¢n báº±ng)
```

**So sÃ¡nh SMOTE vs SMOTENC:**

| Äáº·c Ä‘iá»ƒm                | SMOTE | SMOTENC |
| ----------------------- | ----- | ------- |
| Xá»­ lÃ½ sá»‘ (numerical)    | âœ…    | âœ…      |
| Xá»­ lÃ½ chá»¯ (categorical) | âŒ    | âœ…      |
| DÃ¹ng cho dá»± Ã¡n nÃ y      | âŒ    | âœ…      |

**Káº¿t quáº£:**

- TÄƒng tá»« ~1600 máº«u â†’ ~6000 máº«u
- Má»—i class cÃ³ 1200 máº«u (cÃ¢n báº±ng hoÃ n toÃ n)

---

### **BÆ¯á»šC 9: Chia dá»¯ liá»‡u Train/Test**

```python
X = df_features.drop("cancer_type_detailed", axis=1)  # 12 cá»™t features
y = df_features["cancer_type_detailed"]                # 1 cá»™t target

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,        # 30% dÃ¹ng Ä‘á»ƒ test
    random_state=42,      # Seed Ä‘á»ƒ káº¿t quáº£ giá»‘ng nhau má»—i láº§n cháº¡y
    stratify=y            # Giá»¯ tá»· lá»‡ classes trong train vÃ  test
)

print(f"Train: {X_train.shape[0]} máº«u")  # ~4200 máº«u
print(f"Test: {X_test.shape[0]} máº«u")    # ~1800 máº«u
```

#### â“ Táº¡i sao chia dá»¯ liá»‡u?

**VÃ­ dá»¥ thá»±c táº¿: Há»c vÃ  thi**

```
ğŸ“š Há»c (Train Set):
- Há»c sinh há»c tá»« sÃ¡ch giÃ¡o khoa
- LÃ m bÃ i táº­p trong sÃ¡ch
â†’ X_train, y_train

ğŸ“ Thi (Test Set):
- Äá» thi KHÃC vá»›i bÃ i táº­p Ä‘Ã£ lÃ m
- Äo kháº£ nÄƒng Ã¡p dá»¥ng kiáº¿n thá»©c
â†’ X_test, y_test (Model chÆ°a tháº¥y bao giá»!)
```

**Náº¿u khÃ´ng chia:**

```
âŒ Há»c sinh thuá»™c lÃ²ng Ä‘Ã¡p Ã¡n
âŒ Thi Ä‘Ãºng Ä‘á» Ä‘Ã£ há»c â†’ 100 Ä‘iá»ƒm
âŒ NhÆ°ng gáº·p Ä‘á» má»›i â†’ 0 Ä‘iá»ƒm
â†’ Overfitting!
```

**Tá»· lá»‡ 70/30:**

- 70% train: Äá»§ dá»¯ liá»‡u Ä‘á»ƒ há»c
- 30% test: Äá»§ máº«u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tin cáº­y

**Stratify:**

```python
stratify=y  # Giá»¯ tá»· lá»‡ classes

# Train set:
Class 0: 840 máº«u (70% cá»§a 1200)
Class 1: 840 máº«u
Class 2: 840 máº«u
...

# Test set:
Class 0: 360 máº«u (30% cá»§a 1200)
Class 1: 360 máº«u
Class 2: 360 máº«u
...
```

---

### **BÆ¯á»šC 10: Huáº¥n luyá»‡n mÃ´ hÃ¬nh (Training)**

#### ğŸ—ï¸ Kiáº¿n trÃºc Model: Pipeline

```python
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

pipe = ImbPipeline([
    ("scaler", StandardScaler()),  # BÆ°á»›c 1: Chuáº©n hÃ³a
    ("svc", SVC(                   # BÆ°á»›c 2: PhÃ¢n loáº¡i
        class_weight="balanced",
        random_state=42
    ))
])
```

**Pipeline = DÃ¢y chuyá»n sáº£n xuáº¥t:**

```
Input â†’ [Chuáº©n hÃ³a] â†’ [PhÃ¢n loáº¡i SVM] â†’ Output
  X   â†’   Scaler    â†’       SVC        â†’   Å·
```

#### ğŸ“Š BÆ°á»›c 1: StandardScaler (Chuáº©n hÃ³a)

**Váº¥n Ä‘á»:** CÃ¡c features cÃ³ scale khÃ¡c nhau

```python
lymph_nodes_examined_positive: 0, 1, 2, 3, ...    (0-30)
nottingham_prognostic_index:   2.04, 5.8, ...     (2-7)
```

**Há»‡ quáº£:**

- Feature cÃ³ giÃ¡ trá»‹ lá»›n â†’ áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n model
- Feature cÃ³ giÃ¡ trá»‹ nhá» â†’ bá»‹ "Ã¡t tiáº¿ng"

**Giáº£i phÃ¡p: Standardization**

```python
CÃ´ng thá»©c: z = (x - Î¼) / Ïƒ

Trong Ä‘Ã³:
- x: GiÃ¡ trá»‹ gá»‘c
- Î¼ (mu): GiÃ¡ trá»‹ trung bÃ¬nh (mean)
- Ïƒ (sigma): Äá»™ lá»‡ch chuáº©n (standard deviation)
```

**VÃ­ dá»¥:**

```python
# TrÆ°á»›c chuáº©n hÃ³a
lymph_nodes: [0, 1, 5, 3, 2]    mean=2.2, std=1.8
nottingham:  [2.04, 5.8, 3.2]   mean=3.68, std=1.6

# Sau chuáº©n hÃ³a (StandardScaler)
lymph_nodes: [-1.22, -0.67, 1.56, 0.44, -0.11]  meanâ‰ˆ0, stdâ‰ˆ1
nottingham:  [-1.02, 1.32, -0.30]                meanâ‰ˆ0, stdâ‰ˆ1
```

**Káº¿t quáº£:**

- Táº¥t cáº£ features cÃ³ mean = 0, std = 1
- CÃ¡c features ngang báº±ng nhau vá» scale
- Model há»c tá»‘t hÆ¡n!

#### ğŸ¤– BÆ°á»›c 2: SVC (Support Vector Classifier)

**SVM lÃ  gÃ¬?**

TÆ°á»Ÿng tÆ°á»£ng báº¡n cÃ³ 2 nhÃ³m Ä‘iá»ƒm trÃªn giáº¥y (â— vÃ  â—‹):

```
          |
    â—  â—  |  â—‹  â—‹
    â—  â—  | â—‹  â—‹
  â—    â—  |   â—‹
          |
     ÄÆ°á»ng phÃ¢n cÃ¡ch
```

**Má»¥c tiÃªu SVM:** TÃ¬m Ä‘Æ°á»ng tháº³ng (hay máº·t pháº³ng) phÃ¢n tÃ¡ch 2 nhÃ³m tá»‘t nháº¥t

**Vá»›i nhiá»u classes (multiclass):**

```
SVM dÃ¹ng chiáº¿n lÆ°á»£c "One-vs-Rest":
- Class 0 vs (Class 1,2,3,4)
- Class 1 vs (Class 0,2,3,4)
- Class 2 vs (Class 0,1,3,4)
- Class 3 vs (Class 0,1,2,4)
- Class 4 vs (Class 0,1,2,3)

â†’ 5 bá»™ phÃ¢n loáº¡i nhá»‹ phÃ¢n
â†’ Dá»± Ä‘oÃ¡n: Class nÃ o cÃ³ "confidence" cao nháº¥t
```

**Tham sá»‘ `class_weight="balanced"`:**

```python
# Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh weight theo sá»‘ lÆ°á»£ng máº«u
weight_class_i = n_samples / (n_classes * n_samples_class_i)

â†’ Class Ã­t máº«u â†’ weight cao â†’ model chÃº Ã½ hÆ¡n
```

#### ğŸ”§ Hyperparameter Tuning (GridSearchCV)

**Váº¥n Ä‘á»:** SVM cÃ³ nhiá»u tham sá»‘, giÃ¡ trá»‹ nÃ o tá»‘t nháº¥t?

```python
param_grid = {
    "svc__C": [0.1, 1, 10],              # Regularization
    "svc__kernel": ["linear", "rbf"],     # Loáº¡i kernel
    "svc__gamma": ["scale", "auto"]       # Kernel coefficient
}
```

**Ã nghÄ©a tham sá»‘:**

1. **C (Regularization parameter):**

```
C nhá» (0.1): ÄÆ°á»ng phÃ¢n cÃ¡ch "má»m", cho phÃ©p sai sá»‘
           â†’ TrÃ¡nh overfitting

C lá»›n (10):  ÄÆ°á»ng phÃ¢n cÃ¡ch "cá»©ng", pháº£i chÃ­nh xÃ¡c
           â†’ CÃ³ thá»ƒ overfitting
```

2. **Kernel:**

```
linear: ÄÆ°á»ng tháº³ng phÃ¢n tÃ¡ch
        â— â— | â—‹ â—‹  (Ä‘Æ¡n giáº£n)

rbf:    ÄÆ°á»ng cong phá»©c táº¡p
        â—   â—
          â—‹â—‹
        â—   â—  (linh hoáº¡t hÆ¡n)
```

3. **Gamma:**

```
gamma nhá»: áº¢nh hÆ°á»Ÿng xa (smooth)
gamma lá»›n: áº¢nh hÆ°á»Ÿng gáº§n (chi tiáº¿t)
```

**GridSearchCV = Thá»­ táº¥t cáº£ combinations:**

```python
from sklearn.model_selection import GridSearchCV, StratifiedKFold

grid = GridSearchCV(
    pipe,
    param_grid,
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    scoring="f1_macro",
    n_jobs=-1,      # DÃ¹ng táº¥t cáº£ CPU cores
    verbose=2        # Hiá»ƒn thá»‹ tiáº¿n Ä‘á»™
)

grid.fit(X_train, y_train)
best_pipe = grid.best_estimator_
```

**QuÃ¡ trÃ¬nh:**

```
Tá»•ng sá»‘ combinations: 3 Ã— 2 Ã— 2 = 12 models

Vá»›i má»—i combination, test qua 5 folds:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fold 1: Train[1,2,3,4] â†’ Test[5]      â”‚
â”‚ Fold 2: Train[1,2,3,5] â†’ Test[4]      â”‚
â”‚ Fold 3: Train[1,2,4,5] â†’ Test[3]      â”‚
â”‚ Fold 4: Train[1,3,4,5] â†’ Test[2]      â”‚
â”‚ Fold 5: Train[2,3,4,5] â†’ Test[1]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†’ TÃ­nh F1-score trung bÃ¬nh

Tá»•ng cá»™ng: 12 models Ã— 5 folds = 60 láº§n train!
â†’ Chá»n combination cÃ³ F1-score cao nháº¥t
```

**VÃ­ dá»¥ káº¿t quáº£:**

```
Best params: {
    'svc__C': 1,
    'svc__kernel': 'rbf',
    'svc__gamma': 'scale'
}
â†’ ÄÃ¢y lÃ  model tá»‘t nháº¥t!
```

---

## ğŸ“ˆ ÄÃNH GIÃ MODEL (EVALUATION)

### 1ï¸âƒ£ Accuracy (Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ)

```python
y_pred = best_pipe.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")  # VÃ­ dá»¥: 0.8523 (85.23%)
```

**Ã nghÄ©a:**

```
Accuracy = Sá»‘ dá»± Ä‘oÃ¡n Ä‘Ãºng / Tá»•ng sá»‘ máº«u

VÃ­ dá»¥:
- Test set: 1800 máº«u
- Dá»± Ä‘oÃ¡n Ä‘Ãºng: 1534 máº«u
â†’ Accuracy = 1534/1800 = 85.23%
```

**âš ï¸ Giá»›i háº¡n cá»§a Accuracy:**

```
Náº¿u cÃ³ class imbalance:
Class 1: 1500 máº«u
Class 2: 300 máº«u

Model "lÆ°á»i": "Táº¥t cáº£ lÃ  Class 1!"
â†’ Accuracy = 1500/1800 = 83.3%
â†’ NhÆ°ng Class 2 hoÃ n toÃ n sai!
```

### 2ï¸âƒ£ Classification Report (Chi tiáº¿t tá»«ng class)

```python
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred, digits=4))
```

**Output vÃ­ dá»¥:**

```
                              precision  recall  f1-score  support

                      Breast     0.7500  0.8182  0.7826      360
Breast Invasive Ductal Ca...     0.9012  0.8944  0.8978      360
Breast Invasive Lobular C...     0.8235  0.8500  0.8366      360
Breast Invasive Mixed Muc...     0.8000  0.7778  0.7887      360
Breast Mixed Ductal and L...     0.8571  0.8333  0.8451      360

                  accuracy                        0.8347     1800
                 macro avg     0.8264  0.8347  0.8302     1800
              weighted avg     0.8264  0.8347  0.8302     1800
```

**Giáº£i thÃ­ch metrics:**

#### Precision (Äá»™ chÃ­nh xÃ¡c dá»± Ä‘oÃ¡n)

```
Precision = True Positive / (True Positive + False Positive)

VÃ­ dá»¥ Class 1:
- Model dá»± Ä‘oÃ¡n 100 máº«u lÃ  Class 1
- Trong Ä‘Ã³ 90 máº«u Ä‘Ãºng tháº­t
â†’ Precision = 90/100 = 0.90 (90%)

Ã nghÄ©a: "Khi model nÃ³i Class 1, cÃ³ 90% kháº£ nÄƒng Ä‘Ãºng"
```

#### Recall (Äá»™ bao phá»§)

```
Recall = True Positive / (True Positive + False Negative)

VÃ­ dá»¥ Class 1:
- Thá»±c táº¿ cÃ³ 120 máº«u lÃ  Class 1
- Model tÃ¬m ra Ä‘Æ°á»£c 90 máº«u
â†’ Recall = 90/120 = 0.75 (75%)

Ã nghÄ©a: "Model tÃ¬m Ä‘Æ°á»£c 75% máº«u Class 1"
```

#### F1-Score (Trung bÃ¬nh Ä‘iá»u hÃ²a)

```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)

VÃ­ dá»¥:
- Precision = 0.90
- Recall = 0.75
â†’ F1 = 2 Ã— (0.90 Ã— 0.75) / (0.90 + 0.75) = 0.8182

Ã nghÄ©a: CÃ¢n báº±ng giá»¯a Precision vÃ  Recall
```

**VÃ­ dá»¥ thá»±c táº¿:**

```
ğŸ‘¨â€âš•ï¸ BÃ¡c sÄ© A (High Precision, Low Recall):
- Cháº©n Ä‘oÃ¡n: 10 ngÆ°á»i bá»‹ ung thÆ°
- Káº¿t quáº£: 10/10 Ä‘Ãºng (Precision=100%)
- Thá»±c táº¿: CÃ²n 20 ngÆ°á»i khÃ¡c cÅ©ng bá»‹ nhÆ°ng bá» sÃ³t
â†’ Recall = 10/30 = 33%
â†’ "NÃ³i Ä‘Ãºng nhÆ°ng sÃ³t nhiá»u"

ğŸ‘¨â€âš•ï¸ BÃ¡c sÄ© B (Low Precision, High Recall):
- Cháº©n Ä‘oÃ¡n: 50 ngÆ°á»i bá»‹ ung thÆ°
- Káº¿t quáº£: 30/50 Ä‘Ãºng (Precision=60%)
- Thá»±c táº¿: TÃ¬m Ä‘Æ°á»£c 30/30 ngÆ°á»i bá»‹ (Recall=100%)
â†’ "TÃ¬m háº¿t nhÆ°ng bÃ¡o sai nhiá»u"

âœ… Tá»‘t nháº¥t: F1-Score cao (cÃ¢n báº±ng cáº£ 2)
```

#### Support (Sá»‘ lÆ°á»£ng máº«u)

```
support = Sá»‘ máº«u thá»±c táº¿ cá»§a class Ä‘Ã³ trong test set

VÃ­ dá»¥:
- Class 0: 360 máº«u
- Class 1: 360 máº«u
â†’ Stratified split hoáº¡t Ä‘á»™ng tá»‘t!
```

#### Macro avg vs Weighted avg

```python
# Macro average (khÃ´ng quan tÃ¢m sá»‘ lÆ°á»£ng)
macro_f1 = (f1_class0 + f1_class1 + ... + f1_class4) / 5

# Weighted average (cÃ³ trá»ng sá»‘ theo sá»‘ lÆ°á»£ng)
weighted_f1 = (f1_class0Ã—360 + f1_class1Ã—360 + ...) / 1800
```

### 3ï¸âƒ£ Confusion Matrix (Ma tráº­n nháº§m láº«n)

```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()
```

**VÃ­ dá»¥ Confusion Matrix:**

```
                    Predicted
                0    1    2    3    4
Actual    0  [294  30   18   10    8]   â† 294 Ä‘Ãºng, 66 sai
          1  [ 20 322   12    4    2]   â† 322 Ä‘Ãºng, 38 sai
          2  [ 15  10 306   18   11]   â† 306 Ä‘Ãºng, 54 sai
          3  [  8   5   20 280   47]   â† 280 Ä‘Ãºng, 80 sai
          4  [  6   3   14   48 289]   â† 289 Ä‘Ãºng, 71 sai
```

**CÃ¡ch Ä‘á»c:**

```
HÃ ng 0, Cá»™t 1: 30
â†’ 30 máº«u Class 0 bá»‹ nháº§m thÃ nh Class 1

HÃ ng 3, Cá»™t 4: 47
â†’ 47 máº«u Class 3 bá»‹ nháº§m thÃ nh Class 4

ÄÆ°á»ng chÃ©o chÃ­nh (294, 322, 306, 280, 289):
â†’ Dá»± Ä‘oÃ¡n Ä‘Ãºng!
```

**PhÃ¢n tÃ­ch:**

- Class 1 dá»± Ä‘oÃ¡n tá»‘t nháº¥t (322/360 = 89%)
- Class 0 thÆ°á»ng bá»‹ nháº§m vá»›i Class 1
- Class 3 â†” Class 4 dá»… nháº§m láº«n (cÃ³ thá»ƒ do Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng tá»±)

### 4ï¸âƒ£ ROC-AUC Curves (ÄÆ°á»ng cong ROC)

```python
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize

# Binarize y_test cho multiclass
y_test_bin = label_binarize(y_test, classes=[0,1,2,3,4])

# Láº¥y probability scores
y_score = best_pipe.decision_function(X_test)

# TÃ­nh ROC cho tá»«ng class
for i in range(5):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.3f})')

plt.plot([0,1], [0,1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()
```

**Giáº£i thÃ­ch:**

```
ROC Curve: Äá»“ thá»‹ giá»¯a TPR vs FPR

TPR (True Positive Rate) = Recall
FPR (False Positive Rate) = FP / (FP + TN)

ÄÆ°á»ng chÃ©o (k--): Model ngáº«u nhiÃªn (AUC=0.5)
ÄÆ°á»ng cong cÃ ng cao â†’ Model cÃ ng tá»‘t
AUC = 1.0: Perfect classifier
AUC = 0.5: Random guess
```

**VÃ­ dá»¥ output:**

```
Class 0 (AUC = 0.923)  â† Tá»‘t
Class 1 (AUC = 0.965)  â† Ráº¥t tá»‘t!
Class 2 (AUC = 0.901)  â† Tá»‘t
Class 3 (AUC = 0.878)  â† KhÃ¡ tá»‘t
Class 4 (AUC = 0.887)  â† KhÃ¡ tá»‘t
```

---

## ğŸ’¾ LÆ¯U MODEL

```python
import joblib

# LÆ°u toÃ n bá»™ pipeline (Scaler + SVC)
joblib.dump(best_pipe, "model/best_model.pkl")
print("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c lÆ°u!")
```

**File `best_model.pkl` chá»©a:**

1. **StandardScaler:**

   - Mean vÃ  std cá»§a má»—i feature (Ä‘Ã£ fit trÃªn train set)
   - Äá»ƒ chuáº©n hÃ³a dá»¯ liá»‡u má»›i khi dá»± Ä‘oÃ¡n

2. **SVC:**
   - CÃ¡c support vectors (Ä‘iá»ƒm dá»¯ liá»‡u quan trá»ng)
   - Weights vÃ  bias cá»§a decision boundaries
   - Best hyperparameters tá»« GridSearchCV

**KÃ­ch thÆ°á»›c:** ~2-5 MB (tÃ¹y sá»‘ lÆ°á»£ng support vectors)

**CÃ¡ch load láº¡i:**

```python
loaded_model = joblib.load("model/best_model.pkl")
new_prediction = loaded_model.predict(new_data)
```

---

## ğŸ“Š TÃ“M Táº®T QUY TRÃŒNH

```
ğŸ“ METABRIC Dataset (1906 Ã— 700+)
         â†“
ğŸ” Chá»n 13 features quan trá»ng
         â†“
ğŸ§¹ XÃ³a missing values (â†’ ~1600 máº«u)
         â†“
ğŸ”¢ Label Encoding (chá»¯ â†’ sá»‘)
         â†“
âš–ï¸ SMOTENC (cÃ¢n báº±ng classes â†’ ~6000 máº«u)
         â†“
âœ‚ï¸ Train/Test Split (70/30)
         â†“
ğŸ“ˆ Pipeline: StandardScaler + SVC
         â†“
ğŸ”§ GridSearchCV (12 models Ã— 5 folds)
         â†“
âœ… Best Model (C=1, kernel=rbf, gamma=scale)
         â†“
ğŸ“Š Evaluation:
   â€¢ Accuracy: ~85%
   â€¢ F1-score: ~83%
   â€¢ ROC-AUC: ~0.90
         â†“
ğŸ’¾ LÆ°u model â†’ best_model.pkl
```

---

## ğŸ“ KIáº¾N THá»¨C Ná»€N Táº¢NG

### 1. Machine Learning lÃ  gÃ¬?

```
ğŸ§  Há»c mÃ¡y = MÃ¡y tÃ­nh tá»± há»c tá»« dá»¯ liá»‡u

VÃ­ dá»¥:
- Con ngÆ°á»i: Xem 1000 áº£nh chÃ³ â†’ Nháº­n biáº¿t chÃ³
- Machine: Xem 1000 máº«u ung thÆ° loáº¡i 1 â†’ Nháº­n biáº¿t loáº¡i 1

QuÃ¡ trÃ¬nh:
1. Training: Há»c tá»« dá»¯ liá»‡u cÃ³ nhÃ£n (X_train, y_train)
2. Testing: Dá»± Ä‘oÃ¡n dá»¯ liá»‡u má»›i (X_test) â†’ So sÃ¡nh vá»›i y_test
```

### 2. Supervised Learning (Há»c cÃ³ giÃ¡m sÃ¡t)

```
ğŸ“š Dataset cÃ³ nhÃ£n sáºµn:
Input (X)                  â†’  Output (y)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[surgery=1, her2=0, ...]   â†’  Class 1
[surgery=0, her2=1, ...]   â†’  Class 2
...

Model há»c má»‘i quan há»‡: X â†’ y
Dá»± Ä‘oÃ¡n máº«u má»›i: X_new â†’ y_pred
```

### 3. Classification (PhÃ¢n loáº¡i)

```
BÃ i toÃ¡n: Dá»± Ä‘oÃ¡n nhÃ£n rá»i ráº¡c

VÃ­ dá»¥:
- Binary: [0, 1] - Ung thÆ°/KhÃ´ng ung thÆ°
- Multiclass: [0,1,2,3,4] - 5 loáº¡i ung thÆ° (dá»± Ã¡n nÃ y!)
- Multilabel: [0,1], [1,2], ... - 1 máº«u cÃ³ nhiá»u nhÃ£n
```

### 4. Overfitting vs Underfitting

```
ğŸ“‰ Underfitting (Há»c kÃ©m):
Train accuracy: 60%
Test accuracy:  58%
â†’ Model quÃ¡ Ä‘Æ¡n giáº£n, khÃ´ng há»c Ä‘Æ°á»£c pattern

âœ… Good fit (Vá»«a Ä‘á»§):
Train accuracy: 90%
Test accuracy:  85%
â†’ Model há»c tá»‘t vÃ  generalize Ä‘Æ°á»£c

ğŸ“ˆ Overfitting (Há»c váº¹t):
Train accuracy: 99%
Test accuracy:  70%
â†’ Model há»c thuá»™c train set, khÃ´ng Ã¡p dá»¥ng Ä‘Æ°á»£c cho data má»›i
```

### 5. Cross-Validation (Kiá»ƒm Ä‘á»‹nh chÃ©o)

```
Thay vÃ¬ chia 1 láº§n:
Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Test
  70%              30%

Chia 5 láº§n (5-fold):
Fold 1: [Train Train Train Train Test ]
Fold 2: [Train Train Train Test  Train]
Fold 3: [Train Train Test  Train Train]
Fold 4: [Train Test  Train Train Train]
Fold 5: [Test  Train Train Train Train]

â†’ Má»—i máº«u Ä‘Æ°á»£c test 1 láº§n
â†’ Trung bÃ¬nh 5 láº§n â†’ ÄÃ¡nh giÃ¡ tin cáº­y hÆ¡n
```

---

## ğŸš€ BÆ¯á»šC TIáº¾P THEO

Sau khi train model xong, báº¡n cÃ³ thá»ƒ:

### 1. Sá»­ dá»¥ng model Ä‘á»ƒ dá»± Ä‘oÃ¡n

```python
# Load model
import joblib
model = joblib.load("model/best_model.pkl")

# Chuáº©n bá»‹ dá»¯ liá»‡u má»›i (Ä‘Ã£ encode)
new_patient = {
    'type_of_breast_surgery': 1,        # MASTECTOMY
    'cancer_type': 0,                    # Breast Cancer
    'cellularity': 0,                    # High
    'chemotherapy': 1,                   # Yes
    'pam50_+_claudin-low_subtype': 2,   # LumA
    'neoplasm_histologic_grade': 3,     # Grade 3
    'her2_status': 1,                    # Positive
    'hormone_therapy': 1,                # Yes
    'lymph_nodes_examined_positive': 5,
    'nottingham_prognostic_index': 5.4,
    'pr_status': 1,                      # Positive
    'radio_therapy': 1                   # Yes
}

# Dá»± Ä‘oÃ¡n
import pandas as pd
X_new = pd.DataFrame([new_patient])
prediction = model.predict(X_new)[0]

# Decode káº¿t quáº£
cancer_types = {
    0: "Breast",
    1: "Breast Invasive Ductal Carcinoma",
    2: "Breast Invasive Lobular Carcinoma",
    3: "Breast Invasive Mixed Mucinous Carcinoma",
    4: "Breast Mixed Ductal and Lobular Carcinoma"
}
print(f"Dá»± Ä‘oÃ¡n: {cancer_types[prediction]}")
```

### 2. TÃ­ch há»£p vÃ o Backend API

- File `backend/app.py` Ä‘Ã£ tÃ­ch há»£p model nÃ y
- Táº¡o endpoint `/predict` nháº­n JSON input
- Tráº£ vá» káº¿t quáº£ dá»± Ä‘oÃ¡n cho Frontend

### 3. Cáº£i thiá»‡n model

**Thá»­ cÃ¡c thuáº­t toÃ¡n khÃ¡c:**

- Random Forest
- XGBoost
- Neural Networks
- Ensemble methods

**Feature engineering:**

- Táº¡o interaction features
- Polynomial features
- Feature selection (RFE, LASSO)

**Tuning thÃªm:**

- Thá»­ nhiá»u hyperparameters hÆ¡n
- Nested cross-validation
- Bayesian optimization

---

## â“ CÃ‚U Há»I THÆ¯á»œNG Gáº¶P

### Q1: Táº¡i sao dÃ¹ng SVM mÃ  khÃ´ng pháº£i Decision Tree?

**Tráº£ lá»i:**

```
SVM:
âœ… Tá»‘t cho high-dimensional data
âœ… Effective vá»›i small-medium dataset
âœ… Memory efficient (chá»‰ lÆ°u support vectors)
âŒ Slow khi training vá»›i big data
âŒ KhÃ³ interpret

Decision Tree:
âœ… Dá»… hiá»ƒu, dá»… interpret
âœ… Fast training
âŒ Dá»… overfitting
âŒ KÃ©m stable (data thay Ä‘á»•i chÃºt â†’ tree khÃ¡c háº³n)

â†’ Vá»›i medical data nhá» (~1600 máº«u), SVM lÃ  lá»±a chá»n tá»‘t
```

### Q2: SMOTENC cÃ³ táº¡o dá»¯ liá»‡u "giáº£" khÃ´ng an toÃ n khÃ´ng?

**Tráº£ lá»i:**

```
âœ… An toÃ n vÃ¬:
1. Chá»‰ táº¡o trÃªn TRAIN set
2. TEST set giá»¯ nguyÃªn (dá»¯ liá»‡u tháº­t)
3. Synthetic samples dá»±a trÃªn lÃ¡ng giá»ng thá»±c táº¿

âŒ KhÃ´ng an toÃ n náº¿u:
- Apply SMOTE trÆ°á»›c khi split train/test (data leakage!)
- Táº¡o quÃ¡ nhiá»u synthetic samples (noise)

â†’ Dá»± Ã¡n nÃ y implement Ä‘Ãºng cÃ¡ch!
```

### Q3: Accuracy 85% cÃ³ tá»‘t khÃ´ng?

**Tráº£ lá»i:**

```
TÃ¹y context:

Medical diagnosis:
- YÃªu cáº§u cao: >95%
- 85% lÃ  "khÃ¡ tá»‘t" nhÆ°ng chÆ°a Ä‘á»§ deploy thá»±c táº¿
- Cáº§n improve hoáº·c dÃ¹ng lÃ m cÃ´ng cá»¥ há»— trá»£ (khÃ´ng thay tháº¿ bÃ¡c sÄ©)

Spam detection:
- 85% lÃ  táº¡m Ä‘Æ°á»£c
- Nháº§m thÆ° quan trá»ng thÃ nh spam â†’ Váº¥n Ä‘á»!

Product recommendation:
- 85% lÃ  ráº¥t tá»‘t
- Sai 1 vÃ i gá»£i Ã½ khÃ´ng quÃ¡ nghiÃªm trá»ng

â†’ Vá»›i breast cancer: Cáº§n improve thÃªm!
```

### Q4: CÃ³ thá»ƒ dÃ¹ng Deep Learning khÃ´ng?

**Tráº£ lá»i:**

```
Neural Networks cáº§n:
âœ… Big data (>10,000 máº«u)
âœ… High computational resources
âœ… Lots of hyperparameters to tune

Dá»± Ã¡n nÃ y:
âŒ Small dataset (~1600 máº«u)
âŒ Limited features (13 cá»™t)

â†’ SVM, Random Forest phÃ¹ há»£p hÆ¡n!

Náº¿u cÃ³ thÃªm data:
â†’ CÃ³ thá»ƒ thá»­ CNN/RNN cho gene expression data
â†’ Hoáº·c Transfer Learning tá»« pretrained models
```

### Q5: LÃ m sao biáº¿t model cÃ³ overfitting khÃ´ng?

**Kiá»ƒm tra:**

```python
# 1. So sÃ¡nh train vs test accuracy
train_acc = model.score(X_train, y_train)
test_acc = model.score(X_test, y_test)

if train_acc - test_acc > 0.1:  # ChÃªnh lá»‡ch >10%
    print("âš ï¸ Overfitting!")

# 2. Xem learning curve
from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(
    model, X, y, cv=5
)
# Plot: train_scores vs test_scores
# Náº¿u train cao mÃ  test tháº¥p â†’ Overfitting

# 3. Cross-validation scores
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X_train, y_train, cv=5)
print(f"CV scores: {scores}")
print(f"Mean: {scores.mean():.3f} (+/- {scores.std()*2:.3f})")
# Náº¿u std cao â†’ Model unstable
```

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

### Datasets

- [METABRIC Dataset](https://www.cbioportal.org/study/summary?id=brca_metabric)
- Kaggle: Breast Cancer Wisconsin

### Thuáº­t toÃ¡n

- [SVM Tutorial - StatQuest](https://www.youtube.com/watch?v=efR1C6CvhmE)
- [SMOTE Paper](https://arxiv.org/abs/1106.1813)
- Scikit-learn Documentation

### Books

- "Hands-On Machine Learning" - AurÃ©lien GÃ©ron
- "Introduction to Machine Learning with Python" - Andreas MÃ¼ller
- "Pattern Recognition and Machine Learning" - Christopher Bishop

---

## ğŸ‰ Káº¾T LUáº¬N

Báº¡n Ä‘Ã£ hoÃ n thÃ nh viá»‡c xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh AI dá»± Ä‘oÃ¡n ung thÆ° vÃº tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i:

âœ… **Xá»­ lÃ½ dá»¯ liá»‡u:** Missing values, encoding, balancing  
âœ… **Feature engineering:** Selection, scaling  
âœ… **Model training:** SVM vá»›i hyperparameter tuning  
âœ… **Evaluation:** Accuracy, F1-score, ROC-AUC, Confusion Matrix  
âœ… **Deployment-ready:** LÆ°u model dÆ°á»›i dáº¡ng `.pkl`

**Next steps:**

1. TÃ­ch há»£p vá»›i Backend API (FastAPI)
2. XÃ¢y dá»±ng Frontend UI (React)
3. Deploy lÃªn cloud (AWS/Azure/Heroku)
4. Thu tháº­p feedback vÃ  cáº£i thiá»‡n model

---

**ğŸ“§ Náº¿u cÃ³ tháº¯c máº¯c, hÃ£y:**

- Äá»c láº¡i pháº§n giáº£i thÃ­ch
- Cháº¡y tá»«ng cell trong notebook Ä‘á»ƒ hiá»ƒu
- Thá»­ thay Ä‘á»•i tham sá»‘ vÃ  xem káº¿t quáº£

**Happy Learning! ğŸš€**
